global:
  image:
    registry: docker.io

search:
  # -- Enable Tempo search
  enabled: true

rbac:
  create: true

# tempo:
#   securityContext:
#     capabilities:
#       drop:
#         - ALL
#     readOnlyRootFilesystem: true
#     runAsNonRoot: true
#     runAsUser: 1000

ingester:
  # resources:
  #   limits:
  #     cpu: 0.5
  #     memory: 0.75Gi
  #   requests:
  #     cpu: 0.5
  #     memory: 0.75Gi
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 75
    targetMemoryUtilizationPercentage: 75
  # persistence:
  #   # -- Enable creating PVCs which is required when using boltdb-shipper
  #   enabled: false
  #   # -- Size of persistent disk
  #   size: 10Gi
  #   # -- Storage class to be used.
  #   # If defined, storageClassName: <storageClass>.
  #   # If set to "-", storageClassName: "", which disables dynamic provisioning.
  #   # If empty or set to null, no storageClassName spec is
  #   # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).
  #   storageClass: null
  # config:
  #   # -- Maximum size of a block before cutting it
  #   max_block_bytes: null
  #   # -- Maximum length of time before cutting a block
  #   max_block_duration: null
  #   # -- Duration to keep blocks in the ingester after they have been flushed
  #   complete_block_timeout: null

distributor:
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 75
    targetMemoryUtilizationPercentage: 75
#   resources:
#     limits:
#       cpu: 0.25
#       memory: 0.25Gi
#     requests:
#       cpu: 0.25
#       memory: 0.25Gi

# compactor:
#   resources:
#     llimits:
#       cpu: 0.5
#       memory: 0.75Gi
#     requests:
#       cpu: 0.5
#       memory: 0.75Gi

# querier:
#   resources:
#     llimits:
#       cpu: 0.5
#       memory: 0.75Gi
#     requests:
#       cpu: 0.5
#       memory: 0.75Gi

queryFrontend:
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 75
    targetMemoryUtilizationPercentage: 75
#   resources:
#     llimits:
#       cpu: 0.25
#       memory: 0.25Gi
#     requests:
#       cpu: 0.5
#       memory: 0.25Gi

# memcached:
#   resources:
#     limits:
#       cpu: 0.25
#       memory: 0.25Gi
#     requests:
#       cpu: 0.25
#       memory: 0.25Gi

gateway:
  enabled: true
  ingress:
    enabled: true # Grafana
    ingressClassName: nginx

    hosts:
      - host: mk.tempo.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls:
      # - secretName: tempo-gateway-tls
      - hosts:
          - mk.tempo.192.168.64.35.nip.io
  # resources:
  #   limits:
  #     cpu: 0.25
  #     memory: 0.25Gi
  #   requests:
  #     cpu: 0.25
  #     memory: 0.25Gi

traces:
  jaeger:
    grpc: 
      enabled: false
    thriftBinary: 
      enabled: false
    thriftCompact: 
      enabled: false
    thriftHttp: 
      enabled: false
  zipkin: 
      enabled: false
  otlp:
    http: 
      enabled: false
    grpc: 
      enabled: true
  opencensus: 
      enabled: true # for linkerd
  # -- Enable Tempo to ingest traces from Kafka. Reference: https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/kafkareceiver
  kafka: {}

serviceMonitor:
  enabled: true
  labels:
    # required for prometheus-operator
    release: prometheus-operator

prometheusRule:
  enabled: true
  namespace: null
  annotations: {}
  labels: {}
  groups:
    - name: tempo-rules
      rules:
        - record: job:tempo_request_duration_seconds_bucket:sum_rate
          expr: sum(rate(tempo_request_duration_seconds_bucket[1m])) by (le, job)
        - record: job_route:tempo_request_duration_seconds_bucket:sum_rate
          expr: sum(rate(tempo_request_duration_seconds_bucket[1m])) by (le, job, route)
        - record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
          expr: sum(rate(container_cpu_usage_seconds_total[1m])) by (node, namespace, pod, container)
